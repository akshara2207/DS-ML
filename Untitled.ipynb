{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912de2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of dataframe : \n",
      "   1|24|M|technician|85711\n",
      "0       2|53|F|other|94043\n",
      "1      3|23|M|writer|32067\n",
      "2  4|24|M|technician|43537\n",
      "3       5|33|F|other|15213\n",
      "4   6|42|M|executive|98101\n",
      "Shape :  (942, 1)\n",
      "\n",
      "Dataframe after modifying the default parameter values for read_table: \n",
      "   user_id  age gender  occupation zip_code\n",
      "0        1   24      M  technician    85711\n",
      "1        2   53      F       other    94043\n",
      "2        3   23      M      writer    32067\n",
      "3        4   24      M  technician    43537\n",
      "4        5   33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    " import pandas as pd\n",
    "orders = pd.read_table('http://bit.ly/movieusers')\n",
    "print(\"Overview of dataframe : \")\n",
    "print(orders.head())\n",
    "print(\"Shape : \",orders.shape)\n",
    "print()\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('http://bit.ly/movieusers', sep='|', header=None,\n",
    "names=user_cols)\n",
    "print(\"Dataframe after modifying the default parameter values for read_table: \")\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5b691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e47a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac83e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of UFO data reports: \n",
      "                   City Colors Reported Shape Reported State             Time\n",
      "0                Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1           Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2               Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "3               Abilene             NaN           DISK    KS   6/1/1931 13:00\n",
      "4  New York Worlds Fair             NaN          LIGHT    NY  4/18/1933 19:00\n",
      "\n",
      "Cityseries(sorted):\n",
      "1761     Abbeville\n",
      "17809     Aberdeen\n",
      "2297      Aberdeen\n",
      "9404      Aberdeen\n",
      "389       Aberdeen\n",
      "           ...    \n",
      "12441          NaN\n",
      "15767          NaN\n",
      "15812          NaN\n",
      "16054          NaN\n",
      "16608          NaN\n",
      "Name: City, Length: 18241, dtype: object\n",
      "\n",
      "After creating a new 'Location' Series : \n",
      "                   City Colors Reported Shape Reported State             Time  \\\n",
      "0                Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00   \n",
      "1           Willingboro             NaN          OTHER    NJ  6/30/1930 20:00   \n",
      "2               Holyoke             NaN           OVAL    CO  2/15/1931 14:00   \n",
      "3               Abilene             NaN           DISK    KS   6/1/1931 13:00   \n",
      "4  New York Worlds Fair             NaN          LIGHT    NY  4/18/1933 19:00   \n",
      "\n",
      "                   Location  \n",
      "0                Ithaca, NY  \n",
      "1           Willingboro, NJ  \n",
      "2               Holyoke, CO  \n",
      "3               Abilene, KS  \n",
      "4  New York Worlds Fair, NY  \n",
      "\n",
      "Calculate summary statistics : \n",
      "           City Colors Reported Shape Reported  State              Time  \\\n",
      "count     18215            2882          15597  18241             18241   \n",
      "unique     6475              27             27     52             16145   \n",
      "top     Seattle             RED          LIGHT     CA  11/16/1999 19:00   \n",
      "freq        187             780           2803   2529                27   \n",
      "\n",
      "           Location  \n",
      "count         18215  \n",
      "unique         8028  \n",
      "top     Seattle, WA  \n",
      "freq            187  \n",
      "\n",
      "Column names of ufo dataframe :  Index(['City', 'Colors Reported', 'Shape Reported', 'State', 'Time',\n",
      "       'Location'],\n",
      "      dtype='object')\n",
      "\n",
      "Column name of ufo dataframe after renaming two column names :  Index(['City', 'Colors Reported', 'Shape Reported', 'State', 'Time',\n",
      "       'Location'],\n",
      "      dtype='object')\n",
      "\n",
      "Column name of ufo dataframe after removing two columns(city,state) :  Index(['City', 'Colors Reported', 'Shape Reported', 'State', 'Time',\n",
      "       'Location'],\n",
      "      dtype='object')\n",
      "\n",
      "ufo dataframe after deleting first two rows: \n",
      "                   City Colors Reported Shape Reported State             Time  \\\n",
      "2               Holyoke             NaN           OVAL    CO  2/15/1931 14:00   \n",
      "3               Abilene             NaN           DISK    KS   6/1/1931 13:00   \n",
      "4  New York Worlds Fair             NaN          LIGHT    NY  4/18/1933 19:00   \n",
      "5           Valley City             NaN           DISK    ND  9/15/1934 15:30   \n",
      "6           Crater Lake             NaN         CIRCLE    CA   6/15/1935 0:00   \n",
      "\n",
      "                   Location  \n",
      "2               Holyoke, CO  \n",
      "3               Abilene, KS  \n",
      "4  New York Worlds Fair, NY  \n",
      "5           Valley City, ND  \n",
      "6           Crater Lake, CA  \n"
     ]
    }
   ],
   "source": [
    " import pandas as pd #read a csv file\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports') \n",
    "print(\"Overview of UFO data reports: \")\n",
    "print(ufo.head())\n",
    "print()\n",
    "#series\n",
    "print(\"Cityseries(sorted):\")\n",
    "print(ufo.City.sort_values()) \n",
    "print()\n",
    "ufo['Location'] = ufo.City + ', ' + ufo.State\n",
    "print(\"After creating a new 'Location' Series : \") \n",
    "print(ufo.head())\n",
    "print()\n",
    "print(\"Calculate summary statistics : \") \n",
    "print(ufo.describe())\n",
    "print()\n",
    "print(\"Column names of ufo dataframe : \",ufo.columns) \n",
    "print()\n",
    "# rename two of the columns by using the 'rename' method ufo.rename(columns={'Colors Reported':'Colors_Reported', 'Shape Reported':'Shape_Reported'},inplace=True)\n",
    "print(\"Column name of ufo dataframe after renaming two column names : \",ufo.columns)\n",
    "print()\n",
    "# remove multiple columns at once ufo.drop(['City', 'State'], axis=1, inplace=True)\n",
    "print(\"Column name of ufo dataframe after removing two columns(city,state) : \",ufo.columns)\n",
    "print()\n",
    "# remove multiple rows at once (axis=0 refers to  rows) \n",
    "ufo.drop([0, 1], axis=0, inplace=True)\n",
    "print(\"ufo dataframe after deleting first two rows: \") \n",
    "print(ufo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "84cdf9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of top-rated IMDb movies: \n",
      "   star_rating                     title content_rating   genre  duration  \\\n",
      "0          9.3  The Shawshank Redemption              R   Crime       142   \n",
      "1          9.2             The Godfather              R   Crime       175   \n",
      "2          9.1    The Godfather: Part II              R   Crime       200   \n",
      "3          9.0           The Dark Knight          PG-13  Action       152   \n",
      "4          8.9              Pulp Fiction              R   Crime       154   \n",
      "\n",
      "                                         actors_list  \n",
      "0  [u'Tim Robbins', u'Morgan Freeman', u'Bob Gunt...  \n",
      "1    [u'Marlon Brando', u'Al Pacino', u'James Caan']  \n",
      "2  [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "3  [u'Christian Bale', u'Heath Ledger', u'Aaron E...  \n",
      "4  [u'John Travolta', u'Uma Thurman', u'Samuel L....  \n",
      "\n",
      "Different ways to filter rows of a pandas DataFrame by column value: \n",
      "Example : Filter rows to only show movies with a duration of atleast 200 minutes\n",
      "1.using for loop\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "2.broadcasting\n",
      "     star_rating                                          title  \\\n",
      "2            9.1                         The Godfather: Part II   \n",
      "7            8.9  The Lord of the Rings: The Return of the King   \n",
      "17           8.7                                  Seven Samurai   \n",
      "78           8.4                    Once Upon a Time in America   \n",
      "85           8.4                             Lawrence of Arabia   \n",
      "142          8.3              Lagaan: Once Upon a Time in India   \n",
      "157          8.2                             Gone with the Wind   \n",
      "204          8.1                                        Ben-Hur   \n",
      "445          7.9                           The Ten Commandments   \n",
      "476          7.8                                         Hamlet   \n",
      "630          7.7                                      Malcolm X   \n",
      "767          7.6                It's a Mad, Mad, Mad, Mad World   \n",
      "\n",
      "    content_rating      genre  duration  \\\n",
      "2                R      Crime       200   \n",
      "7            PG-13  Adventure       201   \n",
      "17         UNRATED      Drama       207   \n",
      "78               R      Crime       229   \n",
      "85              PG  Adventure       216   \n",
      "142             PG  Adventure       224   \n",
      "157              G      Drama       238   \n",
      "204              G  Adventure       212   \n",
      "445       APPROVED  Adventure       220   \n",
      "476          PG-13      Drama       242   \n",
      "630          PG-13  Biography       202   \n",
      "767       APPROVED     Action       205   \n",
      "\n",
      "                                           actors_list  \n",
      "2    [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "7    [u'Elijah Wood', u'Viggo Mortensen', u'Ian McK...  \n",
      "17   [u'Toshir\\xf4 Mifune', u'Takashi Shimura', u'K...  \n",
      "78   [u'Robert De Niro', u'James Woods', u'Elizabet...  \n",
      "85   [u\"Peter O'Toole\", u'Alec Guinness', u'Anthony...  \n",
      "142  [u'Aamir Khan', u'Gracy Singh', u'Rachel Shell...  \n",
      "157  [u'Clark Gable', u'Vivien Leigh', u'Thomas Mit...  \n",
      "204  [u'Charlton Heston', u'Jack Hawkins', u'Stephe...  \n",
      "445  [u'Charlton Heston', u'Yul Brynner', u'Anne Ba...  \n",
      "476  [u'Kenneth Branagh', u'Julie Christie', u'Dere...  \n",
      "630  [u'Denzel Washington', u'Angela Bassett', u'De...  \n",
      "767  [u'Spencer Tracy', u'Milton Berle', u'Ethel Me...  \n",
      "\n",
      "3.using 'loc' method\n",
      "     star_rating                                          title  \\\n",
      "2            9.1                         The Godfather: Part II   \n",
      "7            8.9  The Lord of the Rings: The Return of the King   \n",
      "17           8.7                                  Seven Samurai   \n",
      "78           8.4                    Once Upon a Time in America   \n",
      "85           8.4                             Lawrence of Arabia   \n",
      "142          8.3              Lagaan: Once Upon a Time in India   \n",
      "157          8.2                             Gone with the Wind   \n",
      "204          8.1                                        Ben-Hur   \n",
      "445          7.9                           The Ten Commandments   \n",
      "476          7.8                                         Hamlet   \n",
      "630          7.7                                      Malcolm X   \n",
      "767          7.6                It's a Mad, Mad, Mad, Mad World   \n",
      "\n",
      "    content_rating      genre  duration  \\\n",
      "2                R      Crime       200   \n",
      "7            PG-13  Adventure       201   \n",
      "17         UNRATED      Drama       207   \n",
      "78               R      Crime       229   \n",
      "85              PG  Adventure       216   \n",
      "142             PG  Adventure       224   \n",
      "157              G      Drama       238   \n",
      "204              G  Adventure       212   \n",
      "445       APPROVED  Adventure       220   \n",
      "476          PG-13      Drama       242   \n",
      "630          PG-13  Biography       202   \n",
      "767       APPROVED     Action       205   \n",
      "\n",
      "                                           actors_list  \n",
      "2    [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "7    [u'Elijah Wood', u'Viggo Mortensen', u'Ian McK...  \n",
      "17   [u'Toshir\\xf4 Mifune', u'Takashi Shimura', u'K...  \n",
      "78   [u'Robert De Niro', u'James Woods', u'Elizabet...  \n",
      "85   [u\"Peter O'Toole\", u'Alec Guinness', u'Anthony...  \n",
      "142  [u'Aamir Khan', u'Gracy Singh', u'Rachel Shell...  \n",
      "157  [u'Clark Gable', u'Vivien Leigh', u'Thomas Mit...  \n",
      "204  [u'Charlton Heston', u'Jack Hawkins', u'Stephe...  \n",
      "445  [u'Charlton Heston', u'Yul Brynner', u'Anne Ba...  \n",
      "476  [u'Kenneth Branagh', u'Julie Christie', u'Dere...  \n",
      "630  [u'Denzel Washington', u'Angela Bassett', u'De...  \n",
      "767  [u'Spencer Tracy', u'Milton Berle', u'Ethel Me...  \n"
     ]
    }
   ],
   "source": [
    " import pandas as pd\n",
    "# read a dataset of top-rated IMDb movies into a DataFrame \n",
    "movies = pd.read_csv('http://bit.ly/imdbratings') \n",
    "print(\"Dataframe of top-rated IMDb movies: \") \n",
    "print(movies.head())\n",
    "print()\n",
    "print(\"Different ways to filter rows of a pandas DataFrame by column value: \") \n",
    "print(\"Example : Filter rows to only show movies with a duration of atleast 200 minutes\")\n",
    "print(\"1.using for loop\")\n",
    "# create a list in which each element refers to a DataFrame row: True if the row satisfies the condition,False otherwise\n",
    "\n",
    "\n",
    "booleans = []\n",
    "for length in movies.duration:\n",
    "   if length >= 200:\n",
    "    booleans.append(True)\n",
    "   else:\n",
    "    booleans.append(False)\n",
    "is_long = pd.Series(booleans) \n",
    "print(is_long.head())\n",
    "print() \n",
    "print(\"2.broadcasting\")\n",
    "print(movies[movies.duration >= 200])\n",
    "print()\n",
    "print(\"3.using 'loc' method\") \n",
    "print(movies.loc[movies.duration >= 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13b50b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe : \n",
      "   order_id  quantity                              item_name  \\\n",
      "0         1         1           Chips and Fresh Tomato Salsa   \n",
      "1         1         1                                   Izze   \n",
      "2         1         1                       Nantucket Nectar   \n",
      "3         1         1  Chips and Tomatillo-Green Chili Salsa   \n",
      "4         2         2                           Chicken Bowl   \n",
      "\n",
      "                                  choice_description item_price  \n",
      "0                                                NaN     $2.39   \n",
      "1                                       [Clementine]     $3.39   \n",
      "2                                            [Apple]     $3.39   \n",
      "3                                                NaN     $2.39   \n",
      "4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n",
      "\n",
      "String methods in pandas: \n",
      "\n",
      "'item_name' series(in uppercase) : \n",
      "0             CHIPS AND FRESH TOMATO SALSA\n",
      "1                                     IZZE\n",
      "2                         NANTUCKET NECTAR\n",
      "3    CHIPS AND TOMATILLO-GREEN CHILI SALSA\n",
      "4                             CHICKEN BOWL\n",
      "Name: item_name, dtype: object\n",
      "\n",
      "Checks for a substring 'Chicken' in the given dataframe: \n",
      "    order_id  quantity             item_name  \\\n",
      "4          2         2          Chicken Bowl   \n",
      "5          3         1          Chicken Bowl   \n",
      "11         6         1  Chicken Crispy Tacos   \n",
      "12         6         1    Chicken Soft Tacos   \n",
      "13         7         1          Chicken Bowl   \n",
      "\n",
      "                                   choice_description item_price  \n",
      "4   [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n",
      "5   [Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...    $10.98   \n",
      "11  [Roasted Chili Corn Salsa, [Fajita Vegetables,...     $8.75   \n",
      "12  [Roasted Chili Corn Salsa, [Rice, Black Beans,...     $8.75   \n",
      "13  [Fresh Tomato Salsa, [Fajita Vegetables, Rice,...    $11.25   \n",
      "\n",
      "0                                                  NaN\n",
      "1                                         [Clementine]\n",
      "2                                              [Apple]\n",
      "3                                                  NaN\n",
      "4    [Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n",
      "Name: choice_description, dtype: object\n",
      "\n",
      "Examine the data type of each Series: \n",
      "order_id               int64\n",
      "quantity               int64\n",
      "item_name             object\n",
      "choice_description    object\n",
      "item_price            object\n",
      "dtype: object\n",
      "\n",
      "Dataframe after replacing '$' and converting string to float of 'item_price' series: \n",
      "0        2.39\n",
      "1        3.39\n",
      "2        3.39\n",
      "3        2.39\n",
      "4       16.98\n",
      "        ...  \n",
      "4617    11.75\n",
      "4618    11.75\n",
      "4619    11.25\n",
      "4620     8.75\n",
      "4621     8.75\n",
      "Name: item_price, Length: 4622, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    " import pandas as pd\n",
    "# read a dataset of Chipotle orders into a DataFrame \n",
    "orders = pd.read_table('http://bit.ly/chiporders') \n",
    "print(\"Dataframe : \")\n",
    "print(orders.head())\n",
    "print()\n",
    "print(\"String methods in pandas: \")\n",
    "print()\n",
    "print(\"'item_name' series(in uppercase) : \") \n",
    "print(orders.item_name.str.upper().head()) \n",
    "print()\n",
    "print(\"Checks for a substring 'Chicken' in the given dataframe: \")\n",
    "print(orders[orders.item_name.str.contains('Chicken')].head())\n",
    "print()\n",
    "# many pandas string methods support regular expressions (regex) \n",
    "print(orders.choice_description.str.replace('[\\[\\]]', '').head())\n",
    "print()\n",
    "print(\"Examine the data type of each Series: \") \n",
    "print(orders.dtypes)\n",
    "print()\n",
    "print(\"Dataframe after replacing '$' and converting string to float of 'item_price' series: \") \n",
    "print(orders.item_price.str.replace('$', '').astype(float))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a846771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe : \n",
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n",
      "2                           0.7    Africa  \n",
      "3                          12.4    Europe  \n",
      "4                           5.9    Africa  \n",
      "\n",
      "Mean beer servings across the entire dataset:  106.16062176165804\n",
      "Mean\tbeer\tservings\tjust\tfor\tcountries\tin\tAfrica:  61.471698113207545\n",
      "\n",
      "Aggregate functions used with groupby: \n",
      "\n",
      "Mean\tbeer\tservings\tfor\teach\tcontinent:  continent\n",
      "Africa            61.471698\n",
      "Asia              37.045455\n",
      "Europe           193.777778\n",
      "North America    145.434783\n",
      "Oceania           89.687500\n",
      "South America    175.083333\n",
      "Name: beer_servings, dtype: float64\n",
      "Maximum\tbeer\tservings\tfor\teach\tcontinent:  continent\n",
      "Africa           376\n",
      "Asia             247\n",
      "Europe           361\n",
      "North America    285\n",
      "Oceania          306\n",
      "South America    333\n",
      "Name: beer_servings, dtype: int64\n",
      "Multiple aggregation functions can be applied simultaneously: \n",
      "               count        mean  min  max\n",
      "continent                                 \n",
      "Africa            53   61.471698    0  376\n",
      "Asia              44   37.045455    0  247\n",
      "Europe            45  193.777778    0  361\n",
      "North America     23  145.434783    1  285\n",
      "Oceania           16   89.687500    0  306\n",
      "South America     12  175.083333   93  333\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert AlgeriaAngolaBeninBotswanaBurkina FasoBurundiCote d'IvoireCabo VerdeCameroonCentral African RepublicChadComorosCongoDR CongoDjiboutiEgyptEquatorial GuineaEritreaEthiopiaGabonGambiaGhanaGuineaGuinea-BissauKenyaLesothoLiberiaLibyaMadagascarMalawiMaliMauritaniaMauritiusMoroccoMozambiqueNamibiaNigerNigeriaRwandaSao Tome & PrincipeSenegalSeychellesSierra LeoneSomaliaSouth AfricaSudanSwazilandTogoTunisiaUgandaTanzaniaZambiaZimbabwe to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[1;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1492\u001b[0m         values,\n\u001b[1;32m   1493\u001b[0m         how,\n\u001b[1;32m   1494\u001b[0m         axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1495\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1497\u001b[0m     )\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[0;32m--> 959\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[1;32m    960\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    961\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    962\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    963\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    964\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    966\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[1;32m    650\u001b[0m         values,\n\u001b[1;32m    651\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    655\u001b[0m     )\n\u001b[0;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[1;32m    658\u001b[0m     values,\n\u001b[1;32m    659\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    660\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[1;32m    661\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[1;32m    662\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    664\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m--> 497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[1;32m    498\u001b[0m     values,\n\u001b[1;32m    499\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    500\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[1;32m    501\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[1;32m    502\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    503\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    505\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[0;32m--> 541\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow, values\u001b[38;5;241m.\u001b[39mdtype, is_numeric)\n\u001b[1;32m    542\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[0;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1692\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"AlgeriaAngolaBeninBotswanaBurkina FasoBurundiCote d'IvoireCabo VerdeCameroonCentral African RepublicChadComorosCongoDR CongoDjiboutiEgyptEquatorial GuineaEritreaEthiopiaGabonGambiaGhanaGuineaGuinea-BissauKenyaLesothoLiberiaLibyaMadagascarMalawiMaliMauritaniaMauritiusMoroccoMozambiqueNamibiaNigerNigeriaRwandaSao Tome & PrincipeSenegalSeychellesSierra LeoneSomaliaSouth AfricaSudanSwazilandTogoTunisiaUgandaTanzaniaZambiaZimbabwe\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(drinks\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinent\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mbeer_servings\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# specifying a column to which the aggregation function should be applied is not required\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m drinks\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinent\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# allow plots to appear in the notebook\u001b[39;00m\n\u001b[1;32m     19\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[1;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   1859\u001b[0m     )\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[1;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[0;32m-> 1503\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[1;32m   1504\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[1;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1492\u001b[0m         values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1497\u001b[0m     )\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m-> 1503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[0;32m-> 1457\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[1;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[1;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   1859\u001b[0m     )\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11540\u001b[0m     _num_doc,\n\u001b[1;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11555\u001b[0m ):\n\u001b[0;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  11203\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11160\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4668\u001b[0m     )\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum))\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1696\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[1;32m   1697\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1698\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[0;32m-> 1699\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert AlgeriaAngolaBeninBotswanaBurkina FasoBurundiCote d'IvoireCabo VerdeCameroonCentral African RepublicChadComorosCongoDR CongoDjiboutiEgyptEquatorial GuineaEritreaEthiopiaGabonGambiaGhanaGuineaGuinea-BissauKenyaLesothoLiberiaLibyaMadagascarMalawiMaliMauritaniaMauritiusMoroccoMozambiqueNamibiaNigerNigeriaRwandaSao Tome & PrincipeSenegalSeychellesSierra LeoneSomaliaSouth AfricaSudanSwazilandTogoTunisiaUgandaTanzaniaZambiaZimbabwe to numeric"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#read a dataset of alcohol consumption into a DataFrame \n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry') \n",
    "print(\"Dataframe : \")\n",
    "print(drinks.head()) \n",
    "print()\n",
    "print(\"Mean beer servings across the entire dataset: \",drinks.beer_servings.mean())\n",
    "print(\"Mean\tbeer\tservings\tjust\tfor\tcountries\tin\tAfrica: \",drinks[drinks.continent=='Africa'].beer_servings.mean())\n",
    "print()\n",
    "print(\"Aggregate functions used with groupby: \") \n",
    "print()\n",
    "print(\"Mean\tbeer\tservings\tfor\teach\tcontinent: \",drinks.groupby('continent').beer_servings.mean())\n",
    "print(\"Maximum\tbeer\tservings\tfor\teach\tcontinent: \",drinks.groupby('continent').beer_servings.max())\n",
    "print(\"Multiple aggregation functions can be applied simultaneously: \") \n",
    "print(drinks.groupby('continent').beer_servings.agg(['count', 'mean', 'min', 'max']))\n",
    "# specifying a column to which the aggregation function should be applied is not required\n",
    "drinks.groupby('continent').mean()\n",
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# side-by-side bar plot of the DataFrame directly above \n",
    "drinks.groupby('continent').mean().plot(kind='bar')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18aa3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  Colors Reported  Shape Reported  State   Time\n",
      "18236  False             True           False  False  False\n",
      "18237  False             True           False  False  False\n",
      "18238  False             True            True  False  False\n",
      "18239  False            False           False  False  False\n",
      "18240  False             True           False  False  False\n",
      "       City  Colors Reported  Shape Reported  State  Time\n",
      "18236  True            False            True   True  True\n",
      "18237  True            False            True   True  True\n",
      "18238  True            False           False   True  True\n",
      "18239  True             True            True   True  True\n",
      "18240  True            False            True   True  True\n",
      "City                  26\n",
      "Colors Reported    15359\n",
      "Shape Reported      2644\n",
      "State                  0\n",
      "Time                   0\n",
      "dtype: int64\n",
      "(18241, 5)\n",
      "(15575, 5)\n",
      "Shape Reported\n",
      "LIGHT       2803\n",
      "DISK        2122\n",
      "TRIANGLE    1889\n",
      "OTHER       1402\n",
      "CIRCLE      1365\n",
      "Name: count, dtype: int64\n",
      "None\n",
      "Shape Reported\n",
      "VARIOUS     2977\n",
      "LIGHT       2803\n",
      "DISK        2122\n",
      "TRIANGLE    1889\n",
      "OTHER       1402\n",
      "Name: count, dtype: int64\n",
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n",
      "2                           0.7    Africa  \n",
      "3                          12.4    Europe  \n",
      "4                           5.9    Africa  \n",
      "RangeIndex(start=0, stop=193, step=1)\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports') \n",
    "print(ufo.isnull().tail()) \n",
    "print(ufo.notnull().tail()) \n",
    "print(ufo.isnull().sum())\n",
    "print(ufo.shape)\n",
    "# if 'all' values are missing in a row, then drop that row (none are dropped in this case) print(ufo.dropna(how='all').shape)\n",
    "print(ufo.dropna(subset=['City', 'Shape Reported'], how='any').shape) \n",
    "print(ufo['Shape Reported'].value_counts().head())\n",
    "# fill in missing values with a specified value\n",
    "print(ufo['Shape Reported'].fillna(value='VARIOUS', inplace=True)) # confirm that the missing values were filled in\n",
    "print(ufo['Shape Reported'].value_counts().head()) \n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry') \n",
    "print(drinks.head())\n",
    "# every DataFrame has an index (sometimes called the \"row labels\")\n",
    "print(drinks.index)\n",
    "# index and columns both default to integers if you don't define them print(pd.read_table('http://bit.ly/movieusers', header=None, sep='|').head()) # identification: index remains with each row when filtering the DataFrame print(drinks[drinks.continent=='South America'])\n",
    "# selection: select a portion of the DataFrame using the index \n",
    "print(drinks.loc[23, 'beer_servings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a11801ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of dataframe : \n",
      "   1|24|M|technician|85711\n",
      "0       2|53|F|other|94043\n",
      "1      3|23|M|writer|32067\n",
      "2  4|24|M|technician|43537\n",
      "3       5|33|F|other|15213\n",
      "4   6|42|M|executive|98101\n",
      "Shape :  (942, 1)\n",
      "\n",
      "Dataframe after modifying the default parameter values for read_table: \n",
      "   user_id  age gender  occupation zip_code\n",
      "0        1   24      M  technician    85711\n",
      "1        2   53      F       other    94043\n",
      "2        3   23      M      writer    32067\n",
      "3        4   24      M  technician    43537\n",
      "4        5   33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "orders = pd.read_table('http://bit.ly/movieusers')\n",
    "print(\"Overview of dataframe : \")\n",
    "print(orders.head())\n",
    "print(\"Shape : \",orders.shape)\n",
    "print()\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('http://bit.ly/movieusers', sep='|', header=None,\n",
    "names=user_cols)\n",
    "print(\"Dataframe after modifying the default parameter values for read_table: \")\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08f5ba43",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 23) (3240485956.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[82], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Column name of ufo dataframe after renaming two column names :\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 23)\n"
     ]
    }
   ],
   "source": [
    " import pandas as pd\n",
    "#read a csv file\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "print(\"Overview of UFO data reports: \")\n",
    "print(ufo.head())\n",
    "print()\n",
    "#series\n",
    "print(\"Cityseries(sorted):\")\n",
    "print(ufo.City.sort_values())\n",
    "print()\n",
    "ufo['Location'] = ufo.City + ', ' + ufo.State\n",
    "print(\"After creating a new 'Location' Series : \")\n",
    "print(ufo.head())\n",
    "print()\n",
    "print(\"Calculate summary statistics : \")\n",
    "print(ufo.describe())\n",
    "print()\n",
    "print(\"Column names of ufo dataframe : \",ufo.columns)\n",
    "print()\n",
    "# rename two of the columns by using the 'rename' method\n",
    "ufo.rename(columns={'Colors Reported':'Colors_Reported',\n",
    "'Shape Reported':'Shape_Reported'},inplace=True)\n",
    "print(\"Column name of ufo dataframe after renaming two column names :\n",
    "\",ufo.columns)\n",
    "print()\n",
    "# remove multiple columns at once\n",
    "ufo.drop(['City', 'State'], axis=1, inplace=True)\n",
    "print(\"Column name of ufo dataframe after removing two columns(city,state) :\n",
    "\",ufo.columns)\n",
    "print()\n",
    "# remove multiple rows at once (axis=0 refers to rows)\n",
    "ufo.drop([0, 1], axis=0, inplace=True)\n",
    "print(\"ufo dataframe after deleting first two rows: \")\n",
    "print(ufo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "36944fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of top-rated IMDb movies: \n",
      "   star_rating                     title content_rating   genre  duration  \\\n",
      "0          9.3  The Shawshank Redemption              R   Crime       142   \n",
      "1          9.2             The Godfather              R   Crime       175   \n",
      "2          9.1    The Godfather: Part II              R   Crime       200   \n",
      "3          9.0           The Dark Knight          PG-13  Action       152   \n",
      "4          8.9              Pulp Fiction              R   Crime       154   \n",
      "\n",
      "                                         actors_list  \n",
      "0  [u'Tim Robbins', u'Morgan Freeman', u'Bob Gunt...  \n",
      "1    [u'Marlon Brando', u'Al Pacino', u'James Caan']  \n",
      "2  [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "3  [u'Christian Bale', u'Heath Ledger', u'Aaron E...  \n",
      "4  [u'John Travolta', u'Uma Thurman', u'Samuel L....  \n",
      "\n",
      "Different ways to filter rows of a pandas DataFrame by column value: \n",
      "Example : Filter rows to only show movies with a duration of atleast 200 minutes\n",
      "1.using for loop\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "2.broadcasting\n",
      "     star_rating                                          title  \\\n",
      "2            9.1                         The Godfather: Part II   \n",
      "7            8.9  The Lord of the Rings: The Return of the King   \n",
      "17           8.7                                  Seven Samurai   \n",
      "78           8.4                    Once Upon a Time in America   \n",
      "85           8.4                             Lawrence of Arabia   \n",
      "142          8.3              Lagaan: Once Upon a Time in India   \n",
      "157          8.2                             Gone with the Wind   \n",
      "204          8.1                                        Ben-Hur   \n",
      "445          7.9                           The Ten Commandments   \n",
      "476          7.8                                         Hamlet   \n",
      "630          7.7                                      Malcolm X   \n",
      "767          7.6                It's a Mad, Mad, Mad, Mad World   \n",
      "\n",
      "    content_rating      genre  duration  \\\n",
      "2                R      Crime       200   \n",
      "7            PG-13  Adventure       201   \n",
      "17         UNRATED      Drama       207   \n",
      "78               R      Crime       229   \n",
      "85              PG  Adventure       216   \n",
      "142             PG  Adventure       224   \n",
      "157              G      Drama       238   \n",
      "204              G  Adventure       212   \n",
      "445       APPROVED  Adventure       220   \n",
      "476          PG-13      Drama       242   \n",
      "630          PG-13  Biography       202   \n",
      "767       APPROVED     Action       205   \n",
      "\n",
      "                                           actors_list  \n",
      "2    [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "7    [u'Elijah Wood', u'Viggo Mortensen', u'Ian McK...  \n",
      "17   [u'Toshir\\xf4 Mifune', u'Takashi Shimura', u'K...  \n",
      "78   [u'Robert De Niro', u'James Woods', u'Elizabet...  \n",
      "85   [u\"Peter O'Toole\", u'Alec Guinness', u'Anthony...  \n",
      "142  [u'Aamir Khan', u'Gracy Singh', u'Rachel Shell...  \n",
      "157  [u'Clark Gable', u'Vivien Leigh', u'Thomas Mit...  \n",
      "204  [u'Charlton Heston', u'Jack Hawkins', u'Stephe...  \n",
      "445  [u'Charlton Heston', u'Yul Brynner', u'Anne Ba...  \n",
      "476  [u'Kenneth Branagh', u'Julie Christie', u'Dere...  \n",
      "630  [u'Denzel Washington', u'Angela Bassett', u'De...  \n",
      "767  [u'Spencer Tracy', u'Milton Berle', u'Ethel Me...  \n",
      "\n",
      "3.using 'loc' method\n",
      "     star_rating                                          title  \\\n",
      "2            9.1                         The Godfather: Part II   \n",
      "7            8.9  The Lord of the Rings: The Return of the King   \n",
      "17           8.7                                  Seven Samurai   \n",
      "78           8.4                    Once Upon a Time in America   \n",
      "85           8.4                             Lawrence of Arabia   \n",
      "142          8.3              Lagaan: Once Upon a Time in India   \n",
      "157          8.2                             Gone with the Wind   \n",
      "204          8.1                                        Ben-Hur   \n",
      "445          7.9                           The Ten Commandments   \n",
      "476          7.8                                         Hamlet   \n",
      "630          7.7                                      Malcolm X   \n",
      "767          7.6                It's a Mad, Mad, Mad, Mad World   \n",
      "\n",
      "    content_rating      genre  duration  \\\n",
      "2                R      Crime       200   \n",
      "7            PG-13  Adventure       201   \n",
      "17         UNRATED      Drama       207   \n",
      "78               R      Crime       229   \n",
      "85              PG  Adventure       216   \n",
      "142             PG  Adventure       224   \n",
      "157              G      Drama       238   \n",
      "204              G  Adventure       212   \n",
      "445       APPROVED  Adventure       220   \n",
      "476          PG-13      Drama       242   \n",
      "630          PG-13  Biography       202   \n",
      "767       APPROVED     Action       205   \n",
      "\n",
      "                                           actors_list  \n",
      "2    [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "7    [u'Elijah Wood', u'Viggo Mortensen', u'Ian McK...  \n",
      "17   [u'Toshir\\xf4 Mifune', u'Takashi Shimura', u'K...  \n",
      "78   [u'Robert De Niro', u'James Woods', u'Elizabet...  \n",
      "85   [u\"Peter O'Toole\", u'Alec Guinness', u'Anthony...  \n",
      "142  [u'Aamir Khan', u'Gracy Singh', u'Rachel Shell...  \n",
      "157  [u'Clark Gable', u'Vivien Leigh', u'Thomas Mit...  \n",
      "204  [u'Charlton Heston', u'Jack Hawkins', u'Stephe...  \n",
      "445  [u'Charlton Heston', u'Yul Brynner', u'Anne Ba...  \n",
      "476  [u'Kenneth Branagh', u'Julie Christie', u'Dere...  \n",
      "630  [u'Denzel Washington', u'Angela Bassett', u'De...  \n",
      "767  [u'Spencer Tracy', u'Milton Berle', u'Ethel Me...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# read a dataset of top-rated IMDb movies into a DataFrame\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings')\n",
    "print(\"Dataframe of top-rated IMDb movies: \")\n",
    "print(movies.head())\n",
    "print()\n",
    "print(\"Different ways to filter rows of a pandas DataFrame by column value: \")\n",
    "print(\"Example : Filter rows to only show movies with a duration of atleast 200 minutes\")\n",
    "print(\"1.using for loop\")\n",
    "booleans = []\n",
    "for length in movies.duration:\n",
    " if length >= 200:\n",
    "   booleans.append(True)\n",
    " else:\n",
    "   booleans.append(False)\n",
    "is_long = pd.Series(booleans)\n",
    "print(is_long.head())\n",
    "print()\n",
    "print(\"2.broadcasting\")\n",
    "print(movies[movies.duration >= 200])\n",
    "print()\n",
    "print(\"3.using 'loc' method\")\n",
    "print(movies.loc[movies.duration >= 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e15efa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe : \n",
      "   order_id  quantity                              item_name  \\\n",
      "0         1         1           Chips and Fresh Tomato Salsa   \n",
      "1         1         1                                   Izze   \n",
      "2         1         1                       Nantucket Nectar   \n",
      "3         1         1  Chips and Tomatillo-Green Chili Salsa   \n",
      "4         2         2                           Chicken Bowl   \n",
      "\n",
      "                                  choice_description item_price  \n",
      "0                                                NaN     $2.39   \n",
      "1                                       [Clementine]     $3.39   \n",
      "2                                            [Apple]     $3.39   \n",
      "3                                                NaN     $2.39   \n",
      "4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n",
      "\n",
      "String methods in pandas:\n",
      "\n",
      "'item_name' series(in uppercase) : \n",
      "0             CHIPS AND FRESH TOMATO SALSA\n",
      "1                                     IZZE\n",
      "2                         NANTUCKET NECTAR\n",
      "3    CHIPS AND TOMATILLO-GREEN CHILI SALSA\n",
      "4                             CHICKEN BOWL\n",
      "Name: item_name, dtype: object\n",
      "\n",
      "Checks for a substring 'Chicken' in the given dataframe: \n",
      "    order_id  quantity             item_name  \\\n",
      "4          2         2          Chicken Bowl   \n",
      "5          3         1          Chicken Bowl   \n",
      "11         6         1  Chicken Crispy Tacos   \n",
      "12         6         1    Chicken Soft Tacos   \n",
      "13         7         1          Chicken Bowl   \n",
      "\n",
      "                                   choice_description item_price  \n",
      "4   [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n",
      "5   [Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...    $10.98   \n",
      "11  [Roasted Chili Corn Salsa, [Fajita Vegetables,...     $8.75   \n",
      "12  [Roasted Chili Corn Salsa, [Rice, Black Beans,...     $8.75   \n",
      "13  [Fresh Tomato Salsa, [Fajita Vegetables, Rice,...    $11.25   \n",
      "\n",
      "0                                                  NaN\n",
      "1                                         [Clementine]\n",
      "2                                              [Apple]\n",
      "3                                                  NaN\n",
      "4    [Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n",
      "Name: choice_description, dtype: object\n",
      "\n",
      "Examine the data type of each Series: \n",
      "order_id               int64\n",
      "quantity               int64\n",
      "item_name             object\n",
      "choice_description    object\n",
      "item_price            object\n",
      "dtype: object\n",
      "\n",
      "Dataframe after replacing '$' and converting string to float of 'item_price' series: \n",
      "0        2.39\n",
      "1        3.39\n",
      "2        3.39\n",
      "3        2.39\n",
      "4       16.98\n",
      "        ...  \n",
      "4617    11.75\n",
      "4618    11.75\n",
      "4619    11.25\n",
      "4620     8.75\n",
      "4621     8.75\n",
      "Name: item_price, Length: 4622, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    " import pandas as pd\n",
    "# read a dataset of Chipotle orders into a DataFrame\n",
    "orders = pd.read_table('http://bit.ly/chiporders')\n",
    "print(\"Dataframe : \")\n",
    "print(orders.head())\n",
    "print()\n",
    "print(\"String methods in pandas:\") \n",
    "print()\n",
    "print(\"'item_name' series(in uppercase) : \")\n",
    "print(orders.item_name.str.upper().head())\n",
    "print()\n",
    "print(\"Checks for a substring 'Chicken' in the given dataframe: \")\n",
    "print(orders[orders.item_name.str.contains('Chicken')].head())\n",
    "print()\n",
    "# many pandas string methods support regular expressions (regex)\n",
    "print(orders.choice_description.str.replace('[\\[\\]]', '').head())\n",
    "print()\n",
    "print(\"Examine the data type of each Series: \")\n",
    "print(orders.dtypes)\n",
    "print()\n",
    "print(\"Dataframe after replacing '$' and converting string to float of 'item_price' series: \")\n",
    "print(orders.item_price.str.replace('$', '').astype(float))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4a98e432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: \n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "\n",
      "Selecting multiple rows and columns from a pandas DataFrame using 'loc': \n",
      "\n",
      "First row, all columns: \n",
      "City                       Ithaca\n",
      "Colors Reported               NaN\n",
      "Shape Reported           TRIANGLE\n",
      "State                          NY\n",
      "Time               6/1/1930 22:00\n",
      "Name: 0, dtype: object\n",
      "\n",
      "First 3 rows, all columns: \n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "\n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "\n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "\n",
      "First 3 rows, only one column 'City': \n",
      "0         Ithaca\n",
      "1    Willingboro\n",
      "2        Holyoke\n",
      "Name: City, dtype: object\n",
      "\n",
      "First 3 rows, two columns 'City' and 'State': \n",
      "          City State\n",
      "0       Ithaca    NY\n",
      "1  Willingboro    NJ\n",
      "2      Holyoke    CO\n",
      "\n",
      "Accomplish the same thing using double brackets: \n",
      "          City State\n",
      "0       Ithaca    NY\n",
      "1  Willingboro    NJ\n",
      "2      Holyoke    CO\n",
      "\n",
      "First 3 rows, columns 'City' through 'State': \n",
      "          City Colors Reported Shape Reported State\n",
      "0       Ithaca             NaN       TRIANGLE    NY\n",
      "1  Willingboro             NaN          OTHER    NJ\n",
      "2      Holyoke             NaN           OVAL    CO\n",
      "\n",
      "Accomplish the same thing using 'head' and 'drop': \n",
      "          City Colors Reported Shape Reported State\n",
      "0       Ithaca             NaN       TRIANGLE    NY\n",
      "1  Willingboro             NaN          OTHER    NJ\n",
      "2      Holyoke             NaN           OVAL    CO\n",
      "\n",
      "Rows in which the 'City' is 'Oakland', column 'State': \n",
      "1694     CA\n",
      "2144     CA\n",
      "4686     MD\n",
      "7293     CA\n",
      "8488     CA\n",
      "8768     CA\n",
      "10816    OR\n",
      "10948    CA\n",
      "11045    CA\n",
      "12322    CA\n",
      "12941    CA\n",
      "16803    MD\n",
      "17322    CA\n",
      "Name: State, dtype: object\n",
      "\n",
      "Accomplish the same thing using 'chained indexing': \n",
      "1694     CA\n",
      "2144     CA\n",
      "4686     MD\n",
      "7293     CA\n",
      "8488     CA\n",
      "8768     CA\n",
      "10816    OR\n",
      "10948    CA\n",
      "11045    CA\n",
      "12322    CA\n",
      "12941    CA\n",
      "16803    MD\n",
      "17322    CA\n",
      "Name: State, dtype: object\n",
      "\n",
      "Selecting multiple rows and columns from a pandas DataFrame using 'iloc': \n",
      "\n",
      "Rows in positions 0 and 1, columns in positions 0 and 3: \n",
      "          City State\n",
      "0       Ithaca    NY\n",
      "1  Willingboro    NJ\n",
      "\n",
      "Rows in positions 0 through 2 (exclusive), columns in positions 0 through 4(exclusive): \n",
      "          City Colors Reported Shape Reported State\n",
      "0       Ithaca             NaN       TRIANGLE    NY\n",
      "1  Willingboro             NaN          OTHER    NJ\n",
      "\n",
      "Rows in positions 0 through 2 (exclusive), all columns: \n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "print(\"Dataframe: \")\n",
    "print(ufo.head(3))\n",
    "print()\n",
    "print(\"Selecting multiple rows and columns from a pandas DataFrame using 'loc': \")\n",
    "print()\n",
    "#loc method is used to select rows and columns by label\n",
    "print(\"First row, all columns: \")\n",
    "print(ufo.loc[0, :])\n",
    "print()\n",
    "print(\"First 3 rows, all columns: \")\n",
    "print(ufo.loc[[0, 1, 2], :])\n",
    "print()\n",
    "# rows 0 through 2 (inclusive), all columns\n",
    "print(ufo.loc[0:2, :])\n",
    "print()\n",
    "# this implies \"all columns\", but explicitly stating \"all columns\" is better\n",
    "print(ufo.loc[0:2])\n",
    "print()\n",
    "print(\"First 3 rows, only one column 'City': \")\n",
    "print(ufo.loc[0:2, 'City'])\n",
    "print()\n",
    "print(\"First 3 rows, two columns 'City' and 'State': \")\n",
    "print(ufo.loc[0:2, ['City', 'State']])\n",
    "print()\n",
    "print(\"Accomplish the same thing using double brackets: \")\n",
    "#using 'loc' is preferred since it's more explicit\n",
    "print(ufo[['City', 'State']].head(3))\n",
    "print()\n",
    "print(\"First 3 rows, columns 'City' through 'State': \")\n",
    "print(ufo.loc[0:2, 'City':'State'])\n",
    "print()\n",
    "print(\"Accomplish the same thing using 'head' and 'drop': \")\n",
    "print(ufo.head(3).drop('Time', axis=1))\n",
    "print()\n",
    "print(\"Rows in which the 'City' is 'Oakland', column 'State': \")\n",
    "print(ufo.loc[ufo.City=='Oakland', 'State'])\n",
    "print()\n",
    "print(\"Accomplish the same thing using 'chained indexing': \")\n",
    "#using 'loc' is preferred since chained indexing can cause problems\n",
    "print(ufo[ufo.City=='Oakland'].State)\n",
    "print()\n",
    "print(\"Selecting multiple rows and columns from a pandas DataFrame using 'iloc': \")\n",
    "print()\n",
    "print(\"Rows in positions 0 and 1, columns in positions 0 and 3: \")\n",
    "print(ufo.iloc[[0, 1], [0, 3]])\n",
    "print()\n",
    "print(\"Rows in positions 0 through 2 (exclusive), columns in positions 0 through 4(exclusive): \")\n",
    "print(ufo.iloc[0:2, 0:4])\n",
    "print()\n",
    "print(\"Rows in positions 0 through 2 (exclusive), all columns: \")\n",
    "print(ufo.iloc[0:2, :])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af43a447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummy variables in pandas: \n",
      "\n",
      "Dataframe: \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "   female   male\n",
      "0   False   True\n",
      "1    True  False\n",
      "2    True  False\n",
      "3    True  False\n",
      "4   False   True\n",
      "\n",
      "    male\n",
      "0   True\n",
      "1  False\n",
      "2  False\n",
      "3  False\n",
      "4   True\n",
      "\n",
      "   Sex_male\n",
      "0      True\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4      True\n",
      "\n",
      "   Embarked_C  Embarked_Q  Embarked_S\n",
      "0       False       False        True\n",
      "1        True       False       False\n",
      "2       False       False        True\n",
      "3       False       False        True\n",
      "4       False       False        True\n",
      "5       False        True       False\n",
      "6       False       False        True\n",
      "7       False       False        True\n",
      "8       False       False        True\n",
      "9        True       False       False\n",
      "\n",
      "   Embarked_Q  Embarked_S\n",
      "0       False        True\n",
      "1       False       False\n",
      "2       False        True\n",
      "3       False        True\n",
      "4       False        True\n",
      "5        True       False\n",
      "6       False        True\n",
      "7       False        True\n",
      "8       False        True\n",
      "9       False       False\n",
      "\n",
      "Dataframe: \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin  Sex_female  Sex_male  Embarked_C  \\\n",
      "0         A/5 21171   7.2500   NaN       False      True       False   \n",
      "1          PC 17599  71.2833   C85        True     False        True   \n",
      "2  STON/O2. 3101282   7.9250   NaN        True     False       False   \n",
      "3            113803  53.1000  C123        True     False       False   \n",
      "4            373450   8.0500   NaN       False      True       False   \n",
      "\n",
      "   Embarked_Q  Embarked_S  \n",
      "0       False        True  \n",
      "1       False       False  \n",
      "2       False        True  \n",
      "3       False        True  \n",
      "4       False        True  \n",
      "\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \n",
      "0         A/5 21171   7.2500   NaN      True       False        True  \n",
      "1          PC 17599  71.2833   C85     False       False       False  \n",
      "2  STON/O2. 3101282   7.9250   NaN     False       False        True  \n",
      "3            113803  53.1000  C123     False       False        True  \n",
      "4            373450   8.0500   NaN      True       False        True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Creating dummy variables in pandas: \")\n",
    "print()\n",
    "# read the training dataset from Kaggle's Titanic competition\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "print(\"Dataframe: \")\n",
    "print(train.head())\n",
    "print()\n",
    "#use 'get_dummies' to create one column for every possible value\n",
    "print(pd.get_dummies(train.Sex).head())\n",
    "print()\n",
    "# drop the first dummy variable ('female') using the 'iloc' method\n",
    "print(pd.get_dummies(train.Sex).iloc[:, 1:].head())\n",
    "print()\n",
    "# add a prefix to identify the source of the dummy variables\n",
    "print(pd.get_dummies(train.Sex, prefix='Sex').iloc[:, 1:].head())\n",
    "print()\n",
    "# use 'get_dummies' with a feature that has 3 possible values\n",
    "print(pd.get_dummies(train.Embarked, prefix='Embarked').head(10))\n",
    "print()\n",
    "# drop the first dummy variable ('C')\n",
    "print(pd.get_dummies(train.Embarked, prefix='Embarked').iloc[:, 1:].head(10))\n",
    "print()\n",
    "#0, 0 means C 1, 0 means Q 0, 1 means S\n",
    "# reset the DataFrame\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "print(\"Dataframe: \")\n",
    "print(train.head())\n",
    "print()\n",
    "26# pass the DataFrame to 'get_dummies' and specify which columns to dummy (it drops\n",
    "#the original columns)\n",
    "print(pd.get_dummies(train, columns=['Sex', 'Embarked']).head())\n",
    "print()\n",
    "# use the 'drop_first' parameter (new in pandas 0.18) to drop the first dummy variable\n",
    "#for each feature\n",
    "print(pd.get_dummies(train, columns=['Sex', 'Embarked'], drop_first=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0b3c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from a dictionary: \n",
      "    id color\n",
      "a  100   red\n",
      "b  101  blue\n",
      "c  102   red\n",
      "\n",
      "DataFrame from a list of lists: \n",
      "    id color\n",
      "0  100   red\n",
      "1  101  blue\n",
      "2  102   red\n",
      "\n",
      "Numpy array: \n",
      "[[0.06747805 0.62484178]\n",
      " [0.55783246 0.45556938]\n",
      " [0.64108247 0.95140027]\n",
      " [0.27095888 0.08276317]]\n",
      "\n",
      "DataFrame from the above defined NumPy array: \n",
      "        one       two\n",
      "0  0.067478  0.624842\n",
      "1  0.557832  0.455569\n",
      "2  0.641082  0.951400\n",
      "3  0.270959  0.082763\n",
      "\n",
      "DataFrame of student IDs (100 through 109) and test scores (random integers between 60 and 100: \n",
      "   student  test\n",
      "0      100    69\n",
      "1      101    79\n",
      "2      102    75\n",
      "3      103    69\n",
      "4      104    90\n",
      "5      105    76\n",
      "6      106    82\n",
      "7      107    74\n",
      "8      108    89\n",
      "9      109    83\n",
      "\n",
      "         test\n",
      "student      \n",
      "100        68\n",
      "101        94\n",
      "102        85\n",
      "103        71\n",
      "104        82\n",
      "105        83\n",
      "106        65\n",
      "107        75\n",
      "108        94\n",
      "109        68\n",
      "\n",
      "c     round\n",
      "b    square\n",
      "Name: shape, dtype: object\n",
      "\n",
      "    id color   shape\n",
      "a  100   red     NaN\n",
      "b  101  blue  square\n",
      "c  102   red   round\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# create a DataFrame from a dictionary (keys become column names, values become\n",
    "#data) optionally specify the order of columns and define the index\n",
    "df = pd.DataFrame({'id':[100, 101, 102], 'color':['red', 'blue', 'red']}, columns=['id', 'color'],\n",
    "index=['a', 'b', 'c'])\n",
    "print(\"DataFrame from a dictionary: \")\n",
    "print(df)\n",
    "print()\n",
    "# create a DataFrame from a list of lists (each inner list becomes a row)\n",
    "print(\"DataFrame from a list of lists: \")\n",
    "print(pd.DataFrame([[100, 'red'], [101, 'blue'], [102, 'red']], columns=['id', 'color']))\n",
    "print()\n",
    "# create a NumPy array (with shape 4 by 2) and fill it with random numbers between0&1\n",
    "arr = np.random.rand(4, 2)\n",
    "print(\"Numpy array: \")\n",
    "print(arr)\n",
    "print()\n",
    "print(\"DataFrame from the above defined NumPy array: \")\n",
    "print(pd.DataFrame(arr, columns=['one', 'two']))\n",
    "print()\n",
    "print(\"DataFrame of student IDs (100 through 109) and test scores (random integers between 60 and 100: \")\n",
    "print(pd.DataFrame({'student':np.arange(100, 110, 1), 'test':np.random.randint(60, 101,\n",
    "10)}))\n",
    "print()\n",
    "# 'set_index' can be chained with the DataFrame constructor to select an index\n",
    "print(pd.DataFrame({'student':np.arange(100, 110, 1), 'test':np.random.randint(60,\n",
    "101,10)}).set_index('student'))\n",
    "print()\n",
    "# create a new Series using the Series constructor\n",
    "s = pd.Series(['round', 'square'], index=['c', 'b'], name='shape')\n",
    "print(s)\n",
    "print()\n",
    "# concatenate the DataFrame and the Series (use axis=1 to concatenate columns)\n",
    "print(pd.concat([df, s], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06ad29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
